# 机械飞升
此空间用于记录人工智能学习创造路径
<br/>

##  智能
### 2022.05.24
因果学习的很多文章，至少在反事实解释里面，都没有尝试解决最根本的问题，他们还是将模型看作一个黑箱，尝试改进所谓“算法”找到一些所谓“关键因素”。但是还是没有将学习算法变成透明的。要想构建强大的人工智能，我们不能将核心看作进行解决任务的工具。尽管我们最终是要将人工智能作为工具来用的。我们要赋予人工智能强大的思考的能力，而不是学习的能力。我相信智慧不是思考也不是学习。但是相对于学习，思考更应该成为智慧的指标。从自己的感觉上讲，我不想将人类智慧和机器智慧分开来说。但是我还搞不清楚二者的区别，至少没有确定二者是一样的东西时将二者区分开来更加理性，另外为了符合大家的理解，所以目前就就将二者区分开来。就当今局面来说，技术上讲，机器学习的核心是窄通道的映射（我甚至说错了，机器学习的核心大部分内容可能连窄通道的映射都算不上，仅仅是统计的力量），映射效果和效率的提升是当前人工智能研究的核心内容（结构上的核心内容，可能不是最花费精力的内容，但是是这一部分决定了当前人工智能技术的走向）。机器学习以此方式借助算法的助力而达到的发展成果是显著的，但是却没有一个研究者怀疑过这种方法是达不到强人工智能的境界的。研究思考也未必能达到，但是这是下一步应该走的路。因为算法和这种窄通道的映射的活力只是用来热场的。而机器思考的核心是什么？我们会知道的（，但是很可惜不是专家系统）。<br/>
映射认为这个世界可以无限复杂，但是思维是灵活的，思维可以找到世界的简单性和复杂性。“科学的简洁美”。思考可以涉及探索物理世界的简洁解答，也可以涉及思考经济社会的运行规律，甚至思考人的情绪，等等。<br/>
另外，机器学习和机器思考还缺少一个重要因素，探索。人是有探索能力的，所以可以观察世界，提出问题，验证假设，创造不存在的东西（甚至创造不应该存在的东西，比如不受超强约束的强人工智能）。但是现在的人工智能却不是这样，可能是受限于技术，可能是人们已经在一条跑道上熙熙攘攘地狂奔停不下脚步。无论如何，探索能力对强人工智能是必须的。而且除了开始之前的安全保障技术支持，我们不需要什么东西是自己下定决心开始，也不需要给未来强人工智能的世界定一套完整的技术实现路线。我们要开始，开始了才能渐渐成熟技术，认识技术，并发挥技术的力量，将其与其他技术结合发挥更大的作用。<br/>
<br/>
### 2022.05.25
因果学习是基于统计的因果学习，而不是基于理解/解释的因果学习。当然，基于统计的因果学习是更加方便的，简单实用。但是基于统计的因果学习是无法产生思考能力的。我们无法借助基于统计的因果学习创造出原始的思维形式–逻各斯，更别说更高级的思考了。这显示出来了人工智能在技术领域如火如荼而在哲学领域陷入困境的原因–人们将人工智能看作技术而不是看成哲学，将技术手段大施拳脚而不思考哲学在其中的意义，我说的是有（精简而深刻的）体系的哲学框架而不仅仅是思辨至深处便成其为的哲学。其次，人们过于依赖数学其实也是问题的一点体现。当然数学是美的，数学的精简与高深并存。但是数学的高深从来不是智慧的高深，数学是思考，但是当前的数学还不能描述/模拟思考，相反，哲学却一直以来在观察/描述/模拟方面前进着。当然哲学自身是创造不出来智能的，但是没有哲学也是创造不出来智能的。人工智能是技术，但是只要跟智能挂钩的东西，我们就不能仅仅用拙劣的手段尝试技术的垒叠。<br/>
<br/>
### 2022.05.27
我们之所以用统计数据寻找因果关系是因为我们的机器无法获得斩断因果链（do算子）的能力，它们不能干预不能实验。我们用机器寻找因果关系可能也是因为不想实验……但是重点是只有特殊设计的实验才能在广泛的情景下确定因果关系。 要想做到这些，我们需要机器思考和机器的观察能力，干预能力，创造能力。当然一切都要在安全的前提下进行。不过知识创新的前沿一直都是冒险。我们不能投鼠忌器，这里为了安全必须且唯一的核心是：可解释性。我真的不相信人类控制不了一个可解释的机器思考框架。人类可以接受羸弱的神经网络的黑箱为什么就接受不了强劲的可控制的思考框架呢？真正的问题是人类知识的疆界还没有触及思考。我们对于智慧一无所知。学习，思考，，思维，，，智慧。我不想评判人们对于学习的技术性定义的问题。我只想提一点，我们定义学习的时候不能仅仅看着学习，我们需要将其与整条智慧的探索之路结合起来我知道这看起来不可实现因为我们不了解这条探索之路。但是大家都知道猜想是不需要正确的。我们只有投身可能性才可能创造可能性的实现。相反，仅仅看着学习下一个或困难或简单的定义，哪怕有一天恰好获得了一定程度的成功，接下来的路的还是只靠短视的祈福好运，我们的路只会越来越难走。我们不能将成功的每一步都交给运气，或者神明。构建完备的体系，哪怕不知道技术路线，指明一个方向我们也不会陷入绝望的泥潭还心安理得的自我安慰谈笑风生，有了一个方向，我们才不得不尝试不同的方法走出这片海域向下一个岛屿出发。当然这是心理作用，还有技术上的准备衔接继承带来的好处不用多言。<br/>
<br/>
好的转化中，信息可以约等于数据。但是很多转化是不好的。信息生成数据，但是数据不等于信息。现实转化为信息的过程中会产生一部分损失，信息转化为数据的过程中产生一部分损失。人类有分析数据和信息的能力，还拥有进一步窥视现实的能力。但是机器没有，机器面对数据。要么我们将信息更多的转化为有用的（!）数据，要么我们就增进机器转化信息的能力。 现有机器学习对数据的处理尝试再强，获得的内容也是有限的。因为上界已定。<br/>
<br/>
### 2022.05.28
学习是知识的更新过程。知识（在此尝试定义为）：高质量的信息，此种信息可以作为一种结构完善/不完善的系统中的一部分。 这个系统是用来进行思考的信息库，我们给它取名为知识系统。知识系统不是思考的核心，仅仅是思考的前提。<br/>
<br/>
而学习的过程是复杂的，需要知识系统的帮助也就是思考过程的介入。学习不是对所有信息的一视同仁。当今机器学习就是对所有信息过于平等，这是机器的特征。学习是需要知识与知识系统相互作用的。但是在一个思维实验中，我发现知识不能只依赖于学习系统，其中还要有一个东西，我先在此称其为“信仰”，尽管可能“心理/感受”更恰当一点。思维实验如下： 知识系统对知识的处理不能是机器的。这样会导致以后的知识系统被先前的知识系统所定义。但是智慧生物不是这样的。智慧生物可以自我否定。所以知识系统不是一切的根源。真正的决策核心是信仰，在生物中还有心理活动等因素介入。这样的话，在技术上人类也能实现更好地控制。 但是数据如何转化为高质量的信息。而机器思考如何处理这些转化后的信息。前者可以对现有的机器学习技术进行改造而获得一部分。后者就只能需要借助更久之前人工智能先辈的愿景进行新的创造。<br/>
<br/>
### 2022.05.29
比如我之前一直觉得就直接信仰一种意识形态会发生问题。但是不知道为什么。因为我的知识系统里没有这样的判断。但是就感觉而言，我不知道这次的感觉是信仰自由而产生的还是自己不愿意接受不明白的东西产生的。但是我知道当一个东西解释了我的这种感觉之后，我就会定型一种对意识形态的判断，而不是“会发生问题”这种感觉，知识和感觉作用共同更新了知识系统甚至可能还有信仰。再讨论下去就是困难的了。但是机器的信仰是不需要也不应该改变的，这多少会让人类和研发者感到安心。<br/>
<br/>
最后说一句，人工智能的研究不是为了让机器表现的像人一样来迷惑观众，机器学习也不是为了让机器去完成什么任务。你提出一个什么样的问题就得到一个什么样的答案。而我认为这并不总是对的，因为人们可能会自己在心中重新演绎这个问题，就像机器学习他们又把那一个新的问题再次演化为了如何处理数据以获得更好的模型。演化问题本身是科学研究问题的重要一步，而且现如今的机器学习确实有所成就，但是科学想要的更多。技术性的问题偏重于技术性的答案。但是我们研究的是智能。我们的核心问题一直是如何实现智能。我知道这个问题过于庞大繁复，我有生之年可能难以企及。但是提出一些简单的问题来替代这真正关心的问题。我们是得不到正确的结果的甚至找不到正确的方向。要看像终点才能走对路。在一步一步的演化问题的过程中，其实大多是一个一步一步妥协的过程。大多数研究员自认为的项目水准和实际水准差的十万八千里就是这个原因。因为人本身总想要实现高级的技术，而高级的问题是困难的，科学等价地演化分析，还是困难的。所以人们演化的时候会朝简单的方向且自我说服。所以结果不得人心。<br/>
<br/>
含义的冲突使得人们认知受到限制，进而限制人们的活动。政治本身只是关于政客活动的事情。但是当人们把一切社会问题。 这不是重点，重点是机器对概念的认知如何构建？概念构建不同于符号主义。 <br/>
<br/>
### 2022.05.30
机器族群的建立是有用的。但是机器族群不应该过早地受到关注。它可以作为实现基本机器智能后的阶段来看。但是为了实现智能而过早地引入族群概念会增加让对智能的追求走偏的可能性，也会带来更多的未知和因此导致的危险。机器交互也是如此。但这不是反对机器拥有多重思考的能力。因为人本身是会用不同方式思考的。但是这种思考能力是非常有限的，不然可能导致知识系统的崩溃。 机器与人不同的物理基础会是机器智能与人类智能有强大的差异。这种差异的开发是在我们实现基础的机器智能之后，而不是走一步跳两步。往后看不是急功近利，而是为了更好地脚踏实地。<br/>
<br/>
人工智能不是自由意志是机器,是可人为实现的。不是机械主义下的功能机器，但也差不多，差的只是人的自由意志会与之交互使之脱离“必然性”。但除此之外，人工智能就是一个功能机器，没有任何“自由意志”的行生物。 但这些都不足以防比人工智能“反抗”“毁灭人类”，因为人工智能是会思考的，思考结果也能驱动其行动。所以，在以下的即是技术之外应最优先考虑的： 一、完全可控（为人类社会） 二、安全的（为人类和个体） 三、部分可自定义的人（为个人） <br/>
<br/>
### 2022.05.31
A—>中间关联量—>C 因果学习是寻找因果关系的，仅此而已。但是机器思考需要找到作用机制。人为更改一些数据使其有因果联系，哪怕这个因果关系再不合常理，因果学习也是无法否决此因果关系的，只要数据量里面没有人为因素这个变量。或者中间的关联量随便是什么量。 人类也未必能找到一切真相。但是人的知识和思考能力能让人坚信一些事情，比如地球是放的，比如世界上可能有鬼。就像福尔摩斯说的：“排除一切不可能，剩下的一定就是真相。”他凭什么说那些被他排出的是不可能的，因为知识和思考带来的确信。尽管他可能错了。智慧与对错之间非常暧昧，息息相关，但并非一体。<br/>
<br/>
### 2022.

## 理念
<br/>
<br/>
## 技术
<br/>
<br/>
